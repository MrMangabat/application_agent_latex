{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "from utils import split_text_at_punctuation\n",
    "from langchain.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, base, PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.vectorstores import qdrant\n",
    "from config import GPT_API\n",
    "import re\n",
    "from typing import Annotated, List, Dict, TypedDict\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "from utils import check_latex_safety, validate_words\n",
    "os.environ[\"OPENAI_API_KEY\"] = GPT_API\n",
    "\n",
    "current_date = datetime.now().strftime('%B%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_TEMPERATURE = 0.2\n",
    "MODEL = \"gpt-4o-2024-05-13\"#\"gpt-3.5-turbo\"\n",
    "\n",
    "LLM_MODEL = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    name=\"Agent for job applications\",\n",
    "    temperature=SET_TEMPERATURE,\n",
    "    n=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = TextLoader(\"ai_engineer_software_engineer.txt\")\n",
    "\n",
    "loader = DirectoryLoader(path=\"jobtemplates/\")\n",
    "\n",
    "load_applications = loader.load()\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    encode_kwargs = {'normalize_embeddings':False}\n",
    ")\n",
    "\n",
    "vectorstore = qdrant.Qdrant.from_documents(\n",
    "    documents=load_applications,\n",
    "    embedding=embedding_model,\n",
    "    location=\":memory:\"\n",
    ")\n",
    "\n",
    "retriver = vectorstore.as_retriever(search_type=\"similarity\",\n",
    "                                    search_kwargs={'k': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [\n",
    "    ##\n",
    "    \"Business analytics\",\n",
    "    \"Business maturity\",\n",
    "    \"Strategy\",\n",
    "    \"Non-technical and technical communication\",\n",
    "    \"Algorithms & datastrucures\",\n",
    "    \"Software Engineering\",\n",
    "    \"detail oriented\",\n",
    "    \"Creative thinker\",\n",
    "    \"Problem solving\",\n",
    "    \"Critical thinking\",\n",
    "    \"Team player\",\n",
    "    \"Time management\",\n",
    "    \"Adaptability\",\n",
    "    \"Conflict resolution\",\n",
    "    \"Collaborative\",\n",
    "    \"Dilligent\",\n",
    "    \"Software development\",\n",
    "    ## management\n",
    "    \"ITIL\",\n",
    "    \"SAFe\",\n",
    "    \"PRINCE2\",\n",
    "    \"CMMI\",\n",
    "    \"SCRUM\",\n",
    "    \"Agile development\",\n",
    "    \"UML(frequency, class or C4)\",\n",
    "    \"Stakeholder classification\",\n",
    "    ## technical\n",
    "    \"Python intermediate level\",\n",
    "    \"SQL working understanding\",\n",
    "    \"R working understanding\",\n",
    "    \"JavaScript working understanding\",\n",
    "    \"Git\"\n",
    "    \"Statistical modelling\",\n",
    "    \"Fundamental Azure knowledge\",\n",
    "    \"PostGres\",\n",
    "    \"Neo4J\",\n",
    "    \"Qdrant\",\n",
    "    \"ANNOY\",\n",
    "    \"Docker\",\n",
    "    \"scraping\",\n",
    "    \"crawling\",\n",
    "    \"MT5\",\n",
    "    \"Bert\",\n",
    "    \"FinBert\",\n",
    "    \"T5\",\n",
    "    \"Scrapy\",\n",
    "    \"Numpy\",\n",
    "    \"Polars\",\n",
    "    \"Pandas\",\n",
    "    \"FastAPI\",\n",
    "    \"VUE3\",\n",
    "    \"TensorFlow2\",\n",
    "    \"Hyggingface\",\n",
    "    \"Pytorch\",\n",
    "    \"SonarCube\",\n",
    "    \"Seaborn(/matplotlib/Plotly)\",\n",
    "    \"PyTest\",\n",
    "    \"SKlearn\"\n",
    "    \"Unsupervised learning: dimensionality reduction, explorative factor analysis, K-mean..\",\n",
    "    \"Supervised learning: Random Forests, multiple logistic regression, SVP, NNs, Classification\",\n",
    "]\n",
    "\n",
    "\n",
    "do_not_use_words = [\n",
    "    \"abreast\",\n",
    "    \"ardent\",\n",
    "    \"cruisal\",\n",
    "    \"deeply\",\n",
    "    \"eagerly\",\n",
    "    \"endeavors\",\n",
    "    \"enhance\",\n",
    "    \"enhanced\",\n",
    "    \"enhancing\",\n",
    "    \"extensive\",\n",
    "    \"extensively\", \n",
    "    \"expert\",\n",
    "    \"expertise\",\n",
    "    \"facets\"\n",
    "    \"forefront\",\n",
    "    \"fostering\",\n",
    "    \"fueled\",\n",
    "    \"fulfilling\",\n",
    "    \"honed\",\n",
    "    \"intricacies\",\n",
    "    \"intricate\",\n",
    "    \"meticulous \",\n",
    "    \"perfect\",\n",
    "    \"perfectly\",\n",
    "    \"prowess\",\n",
    "    \"profoundly\",\n",
    "    \"realm\",\n",
    "    \"seamlessly\",\n",
    "    \"specialist\",\n",
    "    \"stems\",\n",
    "    \"thrilled\",\n",
    "    \"versed\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_for_search = \"\"\"\n",
    "Engineering\n",
    "In the platform area in Digital Architecture, Data and AI we lay the groundwork for other product teams to delivering accurate, available, and comprehensive data products to enable actionable insights. In addition to this we create trusted and curated enterprise data products that span the entire business of Vestas. This newly established department is an integral component of Vestas' innovative Digital Powerhouse. Our mission is to empower customers, partners, and colleagues to seamlessly discover, access, and connect essential information for informed decisions and impactful actions.\n",
    "Digital Solutions & Development > Digital Solutions > Chapter - Data Engineering & Architecture\n",
    "As a Data Engineer in the platform area, you will collaborate closely with colleagues both inside and outside of the platform area.\n",
    "Your role involves leveraging a range of cloud technologies and tools tailored to the specific product you are working on. This encompasses working with technologies and tools such as Snowflake, databricks, dbt (data build tool) and Azure Services (storage accounts, key vaults).\n",
    "\n",
    "Responsibilities\n",
    "Your key responsibilities will be:\n",
    "Designing, constructing, and maintaining scalable, reliable, and efficient data products\n",
    "Managing and monitoring data products\n",
    "Engaging in close collaboration with stakeholders who consume the data product\n",
    "Establishing necessary integrations with various sources to enable data extraction\n",
    "  \n",
    "Qualifications \n",
    "Degree in Business Intelligence, Data Engineering or Software Development and/or 3 to 5 years of Professional work experience in a similar field\n",
    "Comfortable in a dynamic and changeable working day\n",
    "Comprehensive analytical and problem-solving skills\n",
    "Advanced communication and collaboration skills, with the ability to work effectively in a cross-functional team environment\n",
    "Proficient communication skills in English (our corporate language), Danish is not required\n",
    " \n",
    "Competencies\n",
    "We envision that you possess experience in designing, building, and maintaining data transformation logic. Furthermore, you may see yourself reflected in any of the following categories:\n",
    "Proficiency in programming languages like SQL and Python - experience with dbt, spark, Airflow or Terraform is considered an asset\n",
    "Experience in the development code in a team using devops techniques and agile development methodologies\n",
    "Expertise in working with various Data Warehouse solutions and constructing data products using technologies such as Snowflake, Databricks, Azure Data Engineering Stack (like storage accounts, key vaults, Synapse, MSSQL, etc.)\n",
    "Understanding of data warehouse modelling methodologies (Kimball, data vault et al.) as well as concepts like data mesh or similar\n",
    " \n",
    "On a personal level, we anticipate that you:\n",
    "Possess a collaborative and open-minded nature, eager to contribute to a globally diverse cross-functional team within the organization\n",
    "Display curiosity and motivation for developing innovative data products that generate value exhibing positive communication skills, coupled with a positive, problem-solving approach to accomplishing tasks\n",
    "Thrive in diverse environments and exhibit flexibility in adapting to evolving conditions embracing a commitment to continuous learning and a desire to contribute to the collective growth of the team\n",
    " \n",
    "What we offer \n",
    "\n",
    "You will join a newly established, innovative, and committed team committed to support the business through the development of enterprise data products. You will also have the possibility to be part of forming how to best build data products. You will experience an environment that promotes continuous learning, enabling you to actualize your ambitions and get the chance to work in an agile office environment. While we hold our team members to high individual standards of collaboration, accountability, and meeting deadlines, we provide unwavering support to one another, collectively celebrating successes and addressing challenges.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "semilarity_document_template = vectorstore.similarity_search_with_score(\n",
    "    query = query_for_search,\n",
    "    k = 1,\n",
    "    score_threshold=0.1)\n",
    "\n",
    "# print(\"semilarity_document_template\", semilarity_document_template)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vacancy analysis LLM\n",
    "## Output data structure\n",
    "class OutputStuctureV1(BaseModel):\n",
    "    company_name: str = Field(description=\"identified company name\")\n",
    "    job_title: str = Field(description=\"identified job title\")\n",
    "    analysis_output: str = Field(description=\"analysis of the job vacancy\")\n",
    "    employees_skills_requirement: dict = Field(description=\"identified skills and technical experience required for the job vacancy\")\n",
    "    matching_skills: dict = Field(description=\"matching skills in the job vacancy\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=OutputStuctureV1)\n",
    "\n",
    "system_analysis_template_str = \"\"\"\n",
    "    You are an assisatant to a human resource manager//\n",
    "    You are to assist in the analysis of a job vacancy//\n",
    "    Identify vocal points of interest that the company is looking for//\n",
    "    Identify the company name//\n",
    "    Identify the job title//\n",
    "    Identify the skills and technical experience required for the job vacancy provided here to be stored as a dictionary employee skill requirement//\n",
    "    Use these skills {my_skills} to conduct an analysis between job requirements and find matching skills//\n",
    "    Output should contain a list of matching skills required for the job vacancy//\n",
    "    {format_messages}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "SYSTEM_ANALYSIS_PROMT = SystemMessagePromptTemplate(\n",
    "    prompt = PromptTemplate(\n",
    "        template=system_analysis_template_str,\n",
    "        input_variables=[\"my_skills\"],\n",
    "        partical_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    ")\n",
    "\n",
    "human_analysis_template_str = \"\"\"\n",
    "    Given the job vacancy, you are to analyse the following in detail: {job_position}//\n",
    "    {format_messages}\n",
    "\"\"\"\n",
    "\n",
    "HUMAN_ANALYSIS_PROMPT = HumanMessagePromptTemplate(\n",
    "    prompt = PromptTemplate(\n",
    "        template=human_analysis_template_str,\n",
    "        input_variables=[\"job_position\"],\n",
    "        partical_variables={\"format_messages\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "messages = [SYSTEM_ANALYSIS_PROMT, HUMAN_ANALYSIS_PROMPT]\n",
    "\n",
    "analysis_review_template = ChatPromptTemplate(\n",
    "    input_variables=[\"my_skills\", \"job_position\"],\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "pydantic_formatter = parser.get_format_instructions()\n",
    "\n",
    "generate_analysis_of_job = analysis_review_template | LLM_MODEL | parser\n",
    "analysis_review_template.format_messages(my_skills=skills, job_position=query_for_search, format_messages=pydantic_formatter)\n",
    "\n",
    "\n",
    "analysis_chain = generate_analysis_of_job.invoke({\"job_position\":query_for_search, \"my_skills\":skills, \"format_messages\":pydantic_formatter})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('company_name', 'Vestas')\n",
      "('job_title', 'Data Engineer')\n",
      "('analysis_output', 'The job vacancy for a Data Engineer at Vestas requires a combination of technical and non-technical skills. The role involves designing, constructing, and maintaining data products using a variety of cloud technologies and tools. Key responsibilities include managing data products, collaborating with stakeholders, and establishing data integrations. The ideal candidate should have a degree in Business Intelligence, Data Engineering, or Software Development, or 3 to 5 years of professional experience in a similar field. Proficiency in SQL and Python, experience with dbt, Spark, Airflow, Terraform, and various Data Warehouse solutions are essential. Additionally, the candidate should possess strong analytical, problem-solving, communication, and collaboration skills.')\n",
      "('employees_skills_requirement', {'Degree': 'Business Intelligence, Data Engineering, or Software Development', 'Experience': '3 to 5 years of professional work experience in a similar field', 'Technical Skills': ['SQL', 'Python', 'dbt', 'Spark', 'Airflow', 'Terraform', 'Snowflake', 'Databricks', 'Azure Data Engineering Stack (storage accounts, key vaults, Synapse, MSSQL)'], 'Methodologies': ['DevOps techniques', 'Agile development methodologies', 'Data warehouse modelling methodologies (Kimball, data vault et al.)', 'Data mesh concepts'], 'Non-Technical Skills': ['Analytical and problem-solving skills', 'Advanced communication and collaboration skills', 'Proficient communication skills in English', 'Collaborative and open-minded nature', 'Curiosity and motivation for developing innovative data products', 'Flexibility in adapting to evolving conditions', 'Commitment to continuous learning']})\n",
      "('matching_skills', {'Business analytics': False, 'Business maturity': False, 'Strategy': False, 'Non-technical and technical communication': True, 'Algorithms & datastructures': False, 'Software Engineering': False, 'detail oriented': False, 'Creative thinker': False, 'Problem solving': True, 'Critical thinking': False, 'Team player': True, 'Time management': False, 'Adaptability': True, 'Conflict resolution': False, 'Collaborative': True, 'Dilligent': False, 'Software development': True, 'ITIL': False, 'SAFe': False, 'PRINCE2': False, 'CMMI': False, 'SCRUM': False, 'Agile development': True, 'UML(frequency, class or C4)': False, 'Stakeholder classification': False, 'Python intermediate level': True, 'SQL working understanding': True, 'R working understanding': False, 'JavaScript working understanding': False, 'GitStatistical modelling': False, 'Fundamental Azure knowledge': True, 'PostGres': False, 'Neo4J': False, 'Qdrant': False, 'ANNOY': False, 'Docker': False, 'scraping': False, 'crawling': False, 'MT5': False, 'Bert': False, 'FinBert': False, 'T5': False, 'Scrapy': False, 'Numpy': False, 'Polars': False, 'Pandas': False, 'FastAPI': False, 'VUE3': False, 'TensorFlow2': False, 'Hyggingface': False, 'Pytorch': False, 'SonarCube': False, 'Seaborn(/matplotlib/Plotly)': False, 'PyTest': False, 'SKlearnUnsupervised learning: dimensionality reduction, explorative factor analysis, K-mean..': False, 'Supervised learning: Random Forests, multiple logistic regression, SVP, NNs, Classification': False})\n",
      "analysis_chain company_name='Vestas' job_title='Data Engineer' analysis_output='The job vacancy for a Data Engineer at Vestas requires a combination of technical and non-technical skills. The role involves designing, constructing, and maintaining data products using a variety of cloud technologies and tools. Key responsibilities include managing data products, collaborating with stakeholders, and establishing data integrations. The ideal candidate should have a degree in Business Intelligence, Data Engineering, or Software Development, or 3 to 5 years of professional experience in a similar field. Proficiency in SQL and Python, experience with dbt, Spark, Airflow, Terraform, and various Data Warehouse solutions are essential. Additionally, the candidate should possess strong analytical, problem-solving, communication, and collaboration skills.' employees_skills_requirement={'Degree': 'Business Intelligence, Data Engineering, or Software Development', 'Experience': '3 to 5 years of professional work experience in a similar field', 'Technical Skills': ['SQL', 'Python', 'dbt', 'Spark', 'Airflow', 'Terraform', 'Snowflake', 'Databricks', 'Azure Data Engineering Stack (storage accounts, key vaults, Synapse, MSSQL)'], 'Methodologies': ['DevOps techniques', 'Agile development methodologies', 'Data warehouse modelling methodologies (Kimball, data vault et al.)', 'Data mesh concepts'], 'Non-Technical Skills': ['Analytical and problem-solving skills', 'Advanced communication and collaboration skills', 'Proficient communication skills in English', 'Collaborative and open-minded nature', 'Curiosity and motivation for developing innovative data products', 'Flexibility in adapting to evolving conditions', 'Commitment to continuous learning']} matching_skills={'Business analytics': False, 'Business maturity': False, 'Strategy': False, 'Non-technical and technical communication': True, 'Algorithms & datastructures': False, 'Software Engineering': False, 'detail oriented': False, 'Creative thinker': False, 'Problem solving': True, 'Critical thinking': False, 'Team player': True, 'Time management': False, 'Adaptability': True, 'Conflict resolution': False, 'Collaborative': True, 'Dilligent': False, 'Software development': True, 'ITIL': False, 'SAFe': False, 'PRINCE2': False, 'CMMI': False, 'SCRUM': False, 'Agile development': True, 'UML(frequency, class or C4)': False, 'Stakeholder classification': False, 'Python intermediate level': True, 'SQL working understanding': True, 'R working understanding': False, 'JavaScript working understanding': False, 'GitStatistical modelling': False, 'Fundamental Azure knowledge': True, 'PostGres': False, 'Neo4J': False, 'Qdrant': False, 'ANNOY': False, 'Docker': False, 'scraping': False, 'crawling': False, 'MT5': False, 'Bert': False, 'FinBert': False, 'T5': False, 'Scrapy': False, 'Numpy': False, 'Polars': False, 'Pandas': False, 'FastAPI': False, 'VUE3': False, 'TensorFlow2': False, 'Hyggingface': False, 'Pytorch': False, 'SonarCube': False, 'Seaborn(/matplotlib/Plotly)': False, 'PyTest': False, 'SKlearnUnsupervised learning: dimensionality reduction, explorative factor analysis, K-mean..': False, 'Supervised learning: Random Forests, multiple logistic regression, SVP, NNs, Classification': False}\n"
     ]
    }
   ],
   "source": [
    "for i in analysis_chain:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "print(\"analysis_chain\", analysis_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Degree', 'Business Intelligence, Data Engineering or Software Development'), ('Experience', '3 to 5 years of professional work experience in a similar field'), ('Technologies', ['Snowflake', 'Databricks', 'dbt', 'Azure Services']), ('Programming Languages', ['SQL', 'Python']), ('Methodologies', ['DevOps', 'Agile Development']), ('Data Warehouse Solutions', ['Snowflake', 'Databricks', 'Azure Data Engineering Stack']), ('Data Warehouse Modelling', ['Kimball', 'Data Vault']), ('Concepts', ['Data Mesh']), ('Skills', ['Analytical and problem-solving', 'Advanced communication and collaboration', 'Proficient communication in English'])]\n",
      "[('Business analytics', False), ('Business maturity', False), ('Strategy', False), ('Non-technical and technical communication', True), ('Algorithms & datastructures', False), ('Software Engineering', True), ('detail oriented', False), ('Creative thinker', False), ('Problem solving', True), ('Critical thinking', False), ('Team player', True), ('Time management', False), ('Adaptability', True), ('Conflict resolution', False), ('Collaborative', True), ('Dilligent', False)]\n"
     ]
    }
   ],
   "source": [
    "# Extracting identified information from analysis_chain\n",
    "identified_company_name = analysis_chain.company_name\n",
    "identified_job_title = analysis_chain.job_title\n",
    "identified_skill_requirements = analysis_chain.employees_skills_requirement\n",
    "identified_matching_skills = analysis_chain.matching_skills\n",
    "identified_analysis_output = analysis_chain.analysis_output\n",
    "\n",
    "# Create the output dictionary according to the schema\n",
    "output = {\n",
    "    \"company_name\": identified_company_name,\n",
    "    \"job_title\": identified_job_title,\n",
    "    \"analysis_output\": identified_analysis_output,\n",
    "    \"employees_skills_requirement\": identified_skill_requirements\n",
    "}\n",
    "\n",
    "# Getting keys from the dictionary\n",
    "get_employee_requirements_keys = identified_skill_requirements.keys()\n",
    "\n",
    "# Create an itemgetter object with these keys\n",
    "get_employee_requirements_lists = itemgetter(*get_employee_requirements_keys)\n",
    "\n",
    "# Applying itemgetter to the dictionary to get the lists\n",
    "employee_requirements = get_employee_requirements_lists(identified_skill_requirements)\n",
    "\n",
    "# Zipping keys with their corresponding lists\n",
    "lists_with_employee_requirements = zip(get_employee_requirements_keys, employee_requirements)\n",
    "\n",
    "# If you need to process lists_with_employee_requirements further, you can do so here\n",
    "get_matching_skills_keys = identified_matching_skills.keys()\n",
    "get_matching_skills_lists = itemgetter(*get_matching_skills_keys)\n",
    "matching_skills = get_matching_skills_lists(identified_matching_skills)\n",
    "lists_with_matching_skills = zip(get_matching_skills_keys, matching_skills)\n",
    "# Example usage:\n",
    "# print the output dictionary\n",
    "print(list(lists_with_employee_requirements))\n",
    "print(list(lists_with_matching_skills))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputStuctureV2(BaseModel):\n",
    "    company_name: str = Field(description=\"Company name\")\n",
    "    job_title: str = Field(description=\"Job title\")\n",
    "    introduction: str = Field(description=\"Introduction\")\n",
    "    motivation: str = Field(description=\"Motivation\")\n",
    "    skills: str = Field(description=\"Skills\")\n",
    "    edu_masters: str = Field(description=\"Masters\")\n",
    "    edu_bachelor: str = Field(description=\"Bachelor\")\n",
    "    continued_learning: str = Field(description=\"Continued learning\")\n",
    "    thank_you: str = Field(description=\"Thank you for your time\")\n",
    "\n",
    "cover_letter_parser = PydanticOutputParser(pydantic_object=OutputStuctureV1)\n",
    "\n",
    "system_generate_cover_letter_template_str = \"\"\"\n",
    "    You are to assist in wrting a professional cover latter for a job//\n",
    "    The total amount of characters that can be used is 4000, including white spaces//\n",
    "        \n",
    "    Grammatical correctness is essential//\n",
    "    Use casual business language//\n",
    "    Ensure, the English language is equal to EITLS c1 score//\n",
    "    The template job application must be in English//\n",
    "    200-400 characters for the introduction section//\n",
    "    800-1000 characters for the motivation section//\n",
    "    500-800 characters for the skills section//\n",
    "    560 characters for the masters section//\n",
    "    390 characters for the bachelors section//\n",
    "    300 characters for the continued learning section//\n",
    "    200 characters for the thank you note//\n",
    "    This template is the jobtemplate: {semilarity_jobtemplate}// \n",
    "    {format_cover_letter}\n",
    "    \"\"\"\n",
    "\n",
    "SYSTEM_GENERATE_COVER_LETTER_PROMT = SystemMessagePromptTemplate(\n",
    "    prompt = PromptTemplate(\n",
    "        template=system_analysis_template_str,\n",
    "        input_variables=[\"semilarity_jobtemplate\"],\n",
    "        partical_variables={\"{format_cover_letter}\": cover_letter_parser.get_format_instructions()}\n",
    "    )\n",
    ")\n",
    "\n",
    "human_generate_cover_letter_template_str = \"\"\"\n",
    "I have the following knowledge and skills which can be found in the following dictionary {my_skills}//\n",
    "write two lines to generate a short introduction with interest in IT and AI with inspiration from the {analysis_output}//\n",
    "write motivation with matching pairs {skill_match} and {employee_requirements} and how these can be utilized for the company's benefi//\n",
    "write a section about skills somme of the skills and how they can be utilized for the company's benefit//\n",
    "keep educational background for later access and save the section about masters degree into master and the section about bachelors into bachelor//\n",
    "keep continued learning section and provide short context that I am willing to learn what is necessary for the company and specific role//\n",
    "write a short and consice thank you note to setup a coffee//\n",
    "I DO NOT have prior experience in a professional environment in programming, ONLY academia//\n",
    "I DO have prior experience in project management//\n",
    "Validate, that the generated cover letter is not using any of these words found here {forbidden_words}//\n",
    "\"\"\"\n",
    "\n",
    "HUMAN_GENERATE_COVER_LETTER_PROMPT = HumanMessagePromptTemplate(\n",
    "    prompt = PromptTemplate(\n",
    "        template=human_analysis_template_str,\n",
    "        input_variables=[\"my_skills\", \"analysis_output\", \"skill_match\", \"employee_requirements\",  \"forbidden_words\"],\n",
    "        partical_variables={\"format_cover_letter\": cover_letter_parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "messages = [SYSTEM_GENERATE_COVER_LETTER_PROMT, HUMAN_GENERATE_COVER_LETTER_PROMPT]\n",
    "\n",
    "pydantic_cover_letter_formatter = cover_letter_parser.get_format_instructions()\n",
    "analysis_review_template.format_messages(\n",
    "    my_skills=skills, \n",
    "    analysis_output=analysis_chain,\n",
    "    skill_match=matching_skills,\n",
    "    employee_requirements=employee_requirements, \n",
    "    \n",
    "    \n",
    "    format_cover_letter=pydantic_cover_letter_formatter)\n",
    "# analysis_chain = generate_analysis_of_job.invoke({\"job_position\":job_position, \"my_skills\":a})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 77\u001b[0m\n\u001b[1;32m     64\u001b[0m format_messages_2 \u001b[38;5;241m=\u001b[39m TEXT_GENERATION_PROMPT\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     65\u001b[0m     analysis_output \u001b[38;5;241m=\u001b[39m identified_analysis_output,\n\u001b[1;32m     66\u001b[0m     employee_requirements \u001b[38;5;241m=\u001b[39m lists_with_employee_requirements,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     forbidden_words \u001b[38;5;241m=\u001b[39m do_not_use_words,\n\u001b[1;32m     71\u001b[0m     format_instructions_2 \u001b[38;5;241m=\u001b[39m parser_2\u001b[38;5;241m.\u001b[39mget_format_instructions())\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# messages = format_messages_2\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# print(type(messages))\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m generate_letter \u001b[38;5;241m=\u001b[39m \u001b[43mformat_messages_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLLM_MODEL\u001b[49m \u001b[38;5;241m|\u001b[39m parser_2\n\u001b[1;32m     79\u001b[0m analysis_chain_2 \u001b[38;5;241m=\u001b[39m generate_letter\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: cover_letter_template})\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langchain_core/runnables/base.py:440\u001b[0m, in \u001b[0;36mRunnable.__ror__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    432\u001b[0m     other: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m     ],\n\u001b[1;32m    438\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunnableSerializable[Other, Output]:\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compose this runnable with another object to create a RunnableSequence.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langchain_core/runnables/base.py:4891\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   4889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableParallel(thing))\n\u001b[1;32m   4890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4892\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4893\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4894\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "TEXT_GENERATION_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',\"\"\"\n",
    "         You are to assist in wrting a professional cover latter for a job//\n",
    "         The total amount of characters that can be used is 4000, including white spaces//\n",
    "         \n",
    "         Grammatical correctness is essential//\n",
    "         Use casual business language//\n",
    "         Ensure, the English language is equal to EITLS c1 score//\n",
    "         The template job application must be in English//\n",
    "         200-300 characters for the introduction section//\n",
    "         800-1000 characters for the motivation section//\n",
    "         500-800 characters for the skills section//\n",
    "         560 characters for the masters section//\n",
    "         390 characters for the bachelors section//\n",
    "         300 characters for the continued learning section//\n",
    "         200 characters for the thank you note//\n",
    "         This template is the jobtemplate: {semilarity_jobtemplate}// \n",
    "         I have the following knowledge and skills which can be found in the following dictionary {skills}//\n",
    "         \n",
    "         write two lines to generate a short introduction with interest in IT and AI with inspiration from the {analysis_output}//\n",
    "         \n",
    "         write motivation with matching pairs {skill_match} and {employee_requirements} and how these can be utilized for the company's benefi//\n",
    "         \n",
    "         write a section about skills somme of the skills and how they can be utilized for the company's benefit//\n",
    "\n",
    "         keep educational background for later access and save the section about masters degree into latex_edu_master and the section about bachelors into latex_edu_bachelor//\n",
    "         keep continued learning section and provide short context that I am willing to learn what is necessary for the company and specific role//\n",
    "        \n",
    "         write a short and consice thank you note to setup a cofee//\n",
    "\n",
    "         I DO NOT have prior experience in a professional environment in programming, ONLY academia//\n",
    "         I DO have prior experience in project management//\n",
    "\n",
    "         Validate, that the generated applicover letter is not using any of these words found here {forbidden_words}//\n",
    "         {format_instructions_2}\n",
    "         \n",
    "        \"\"\"),\n",
    "\n",
    "        ('placeholder','{messages}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cover_letter_template = retriver.get_relevant_documents(query_for_search)\n",
    "\n",
    "# str_cover_letter_template = cover_letter_template[0][0].page_content\n",
    "# print(\"cover_letter_template\", str_cover_letter_template)\n",
    "\n",
    "## Output data structure\n",
    "class OutputStuctureV2(BaseModel):\n",
    "    company_name: str = Field(description=\"Company name\")\n",
    "    job_title: str = Field(description=\"Job title\")\n",
    "    introduction: str = Field(description=\"Introduction\")\n",
    "    motivation: str = Field(description=\"Motivation\")\n",
    "    skills: str = Field(description=\"Skills\")\n",
    "    edu_masters: str = Field(description=\"Masters\")\n",
    "    edu_bachelor: str = Field(description=\"Bachelor\")\n",
    "    continued_learning: str = Field(description=\"Continued learning\")\n",
    "    thank_you: str = Field(description=\"Thank you for your time\")\n",
    "\n",
    "\n",
    "parser_2 = PydanticOutputParser(pydantic_object=OutputStuctureV2)\n",
    "\n",
    "format_messages_2 = TEXT_GENERATION_PROMPT.format(\n",
    "    analysis_output = identified_analysis_output,\n",
    "    employee_requirements = lists_with_employee_requirements,\n",
    "    skill_match = lists_with_matching_skills,\n",
    "    skills = skills_dict,\n",
    "    semilarity_jobtemplate = semilarity_document_template,\n",
    "    forbidden_words = do_not_use_words,\n",
    "    format_instructions_2 = parser_2.get_format_instructions())\n",
    "\n",
    "\n",
    "# messages = format_messages_2\n",
    "# print(type(messages))\n",
    "\n",
    "generate_letter = format_messages_2 | LLM_MODEL | parser_2\n",
    "\n",
    "analysis_chain_2 = generate_letter.invoke({'context': cover_letter_template})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analysis_chain_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[43manalysis_chain_2\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'analysis_chain_2' is not defined"
     ]
    }
   ],
   "source": [
    "print(str(analysis_chain_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 3\n",
    "\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    TypedDict for the graph state.\n",
    "\n",
    "    Args:\n",
    "        TypedDict: Base class for TypedDict.\n",
    "    \"\"\"\n",
    "    error: str\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    generation: str\n",
    "    iterations: int\n",
    "\n",
    "def retrieve_cover_letter(state: GraphState) -> GraphState:\n",
    "    \n",
    "    # State\n",
    "    messages = state['messages']\n",
    "    # iterations = state['iterations']\n",
    "    # error = state['error']\n",
    "    print(\"------ Retrieving cover letter template ------\")\n",
    "    cover_letter_template = vectorstore.similarity_search_with_score(\n",
    "    query = query_for_search,\n",
    "    k = 1,\n",
    "    score_threshold=0.1)\n",
    "\n",
    "    str_cover_letter_template = cover_letter_template[0][0].page_content\n",
    "    print(\"cover_letter_template\", str_cover_letter_template)\n",
    "    print(type(cover_letter_template))\n",
    "\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        # \"iterations\": iterations,\n",
    "        # \"error\": error,\n",
    "        \"cover_letter_template\": str_cover_letter_template,\n",
    "    }\n",
    "\n",
    "def analyse_vacancy(state: GraphState) -> GraphState:\n",
    "    \n",
    "    print(\"------ Analysing vacancy ------\")\n",
    "    print(\"state\", state)\n",
    "    # State\n",
    "    messages = state['messages']\n",
    "    iterations = state['iterations']\n",
    "    error = state['error']\n",
    "    cover_letter_template = state['cover_letter_template']\n",
    "    \n",
    "    generation = generate_letter.invoke({'context': lambda x: cover_letter_template, 'messages': messages})\n",
    "    print('------ CONDUCTING ANALYSIS ------')\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": error,\n",
    "        \"generation\": generation\n",
    "    }\n",
    "    \n",
    "\n",
    "def generate_application(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Generate a job application based on the job template provided.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The current graph state.\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation.\n",
    "    \"\"\"\n",
    "    print(\"------ Generating application ------\")\n",
    "\n",
    "    # State\n",
    "    messages = state['messages']\n",
    "    iterations = state['iterations']\n",
    "    error = state['error']\n",
    "    generation = state['generation']\n",
    "    # Generate solution\n",
    "    application_solution = generate_letter.invoke(messages)\n",
    "\n",
    "\n",
    "    messages += [\n",
    "            ('assistant', f'Here is the attemt to generate a professional cover letter: {application_solution.introduction} {application_solution.motivation} {application_solution.skills} {application_solution.edu_masters} {application_solution.edu_bachelor} {application_solution.continued_learning} {application_solution.thank_you}')\n",
    "        ]\n",
    "\n",
    "\n",
    "    \n",
    "    # Increment iterations\n",
    "    iterations = iterations + 1\n",
    "\n",
    "    return {\n",
    "        \"generation\": generation,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": error\n",
    "    }\n",
    "    \n",
    "def check_generation(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Check the generated application for errors.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The current graph state.\n",
    "\n",
    "    Returns:\n",
    "        state (GraphState): Updated graph state with error status.\n",
    "    \"\"\"\n",
    "\n",
    "    # State\n",
    "    messages = state['messages']\n",
    "    iterations = state['iterations']\n",
    "    error = state['error']\n",
    "    generation = state['generation']\n",
    "    \n",
    "    # Access solution components\n",
    "    try:\n",
    "        print(\"---APPLICATION CHECK: START---\")\n",
    "\n",
    "        # Validate words\n",
    "        # print('pre IF statement for validate words')\n",
    "        # forbidden_words_used = validate_words(do_not_use_words)\n",
    "        # if forbidden_words_used:\n",
    "        #     print('inside IT statement forbidden words used:')\n",
    "        #     raise ValueError(f\"Forbidden words used: {', '.join(forbidden_words_used)}\")\n",
    "\n",
    "        # # Check LaTeX safety\n",
    "        # safe_texts = check_latex_safety(company_name, job_title, introduction, motivation, skills, continued_learning, thank_you)\n",
    "        # if any(text != original for text, original in zip(safe_texts, [company_name, job_title, introduction, motivation, skills, continued_learning, thank_you])):\n",
    "        #     raise ValueError(\"LaTeX safety issues found in the generated application\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"---APPLICATION CHECK: FAILED---\")\n",
    "        error_message = [(\n",
    "            \"user\", f\"Your generated application failed with: {e} because of {do_not_use_words}. Reflect and review on this error and prior attempts to solve the issue. #1 state what you think went wrong and #2 try and solve this problem again. Return full solution. Use the output structure with company_name, job_title, introduction, motivation, skills, masters, bachelors, continued_learning, thank_you.\")]\n",
    "        messages += error_message\n",
    "        error = \"yes\"\n",
    "    else:\n",
    "        print(\"---NO APPLICATION ERRORS---\")\n",
    "        error = \"no\"\n",
    "    \n",
    "    return {\n",
    "        \"generation\": generation,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": error\n",
    "    }\n",
    "\n",
    "\n",
    "def decide_to_finish(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether to finish or retry based on the error status and iteration count.\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The current graph state.\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call.\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations >= max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        return \"generate\"\n",
    "\n",
    "#### Utilities\n",
    "import uuid \n",
    "def _print_event(event: dict, _printed: set, max_length: int = 15000) -> None:\n",
    "    \"\"\"\n",
    "    Prints the current state and the latest message from an event, \n",
    "    ensuring the message is not printed more than once and truncating if necessary.\n",
    "\n",
    "    Args:\n",
    "        event (dict): The event dictionary containing dialog state and messages.\n",
    "        _printed (set): A set of message IDs that have already been printed.\n",
    "        max_length (int): The maximum length of the message to print.\n",
    "    \"\"\"\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(f\"Currently in: {current_state[-1]}\")\n",
    "\n",
    "    messages = event.get(\"messages\")\n",
    "    if messages:\n",
    "        if isinstance(messages, list):\n",
    "            latest_message = messages[-1]\n",
    "        else:\n",
    "            latest_message = messages\n",
    "\n",
    "        # Check if latest_message is a dictionary and has an 'id' attribute\n",
    "        if isinstance(latest_message, dict) and 'id' in latest_message:\n",
    "            message_id = latest_message['id']\n",
    "            if message_id not in _printed:\n",
    "                msg_repr = latest_message.get('pretty_repr', lambda html: str(latest_message))(html=True)\n",
    "                if len(msg_repr) > max_length:\n",
    "                    msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "                print(msg_repr)\n",
    "                _printed.add(message_id)\n",
    "        elif isinstance(latest_message, str):\n",
    "            # If latest_message is a string, print it directly\n",
    "            if latest_message not in _printed:\n",
    "                if len(latest_message) > max_length:\n",
    "                    latest_message = latest_message[:max_length] + \" ... (truncated)\"\n",
    "                print(latest_message)\n",
    "                _printed.add(latest_message)\n",
    "        else:\n",
    "            print(\"Unrecognized message format.\")\n",
    "\n",
    "# # Example usage\n",
    "# _printed = set()\n",
    "# example_event = {\n",
    "#     \"dialog_state\": [\"state1\", \"state2\"],\n",
    "#     \"messages\": [\n",
    "#         {\"id\": \"msg1\", \"pretty_repr\": lambda html: \"This is a test message.\"},\n",
    "#         {\"id\": \"msg2\", \"pretty_repr\": lambda html: \"This is another test message.\"}\n",
    "#     ]\n",
    "# }\n",
    "# _print_event(example_event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Initialize the graph\n",
    "work_flow = StateGraph(GraphState)\n",
    "\n",
    "\n",
    "# Define the nodes\n",
    "work_flow.add_node(\"retrieve_cover_letter\", retrieve_cover_letter)  # retrieve cover letter\n",
    "work_flow.add_node(\"analyse_vacancy\", analyse_vacancy)  # analyse vacancy\n",
    "work_flow.add_node(\"generate_application\", generate_application)  # generation solution\n",
    "work_flow.add_node(\"check_generation\", check_generation)  # check generation\n",
    "\n",
    "# Build graph\n",
    "work_flow.set_entry_point(\"retrieve_cover_letter\")\n",
    "work_flow.add_edge(\"retrieve_cover_letter\", \"analyse_vacancy\")\n",
    "work_flow.add_edge(\"analyse_vacancy\", \"generate_application\")\n",
    "work_flow.add_edge(\"generate_application\", \"check_generation\")\n",
    "work_flow.add_conditional_edges(\n",
    "    \"check_generation\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"generate\": \"generate_application\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set up the memory and compile the graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = work_flow.compile(checkpointer=memory)\n",
    "\n",
    "# Display the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying the graph: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engineering\n",
      "In the platform area in Digital Architecture, Data and AI we lay the groundwork for other product teams to delivering accurate, available, and comprehensive data products to enable actionable insights. In addition to this we create trusted and curated enterprise data products that span the entire business of Vestas. This newly established department is an integral component of Vestas' innovative Digital Powerhouse. Our mission is to empower customers, partners, and colleagues to seamlessly discover, access, and connect essential information for informed decisions and impactful actions.\n",
      "Digital Solutions & Development > Digital Solutions > Chapter - Data Engineering & Architecture\n",
      "As a Data Engineer in the platform area, you will collaborate closely with colleagues both inside and outside of the platform area.\n",
      "Your role involves leveraging a range of cloud technologies and tools tailored to the specific product you are working on. This encompasses working with technologies and tools such as Snowflake, databricks, dbt (data build tool) and Azure Services (storage accounts, key vaults).\n",
      "\n",
      "Responsibilities\n",
      "Your key responsibilities will be:\n",
      "Designing, constructing, and maintaining scalable, reliable, and efficient data products\n",
      "Managing and monitoring data products\n",
      "Engaging in close collaboration with stakeholders who consume the data product\n",
      "Establishing necessary integrations with various sources to enable data extraction\n",
      "  \n",
      "Qualifications \n",
      "Degree in Business Intelligence, Data Engineering or Software Development and/or 3 to 5 years of Professional work experience in a similar field\n",
      "Comfortable in a dynamic and changeable working day\n",
      "Comprehensive analytical and problem-solving skills\n",
      "Advanced communication and collaboration skills, with the ability to work effectively in a cross-functional team environment\n",
      "Proficient communication skills in English (our corporate language), Danish is not required\n",
      " \n",
      "Competencies\n",
      "We envision that you possess experience in designing, building, and maintaining data transformation logic. Furthermore, you may see yourself reflected in any of the following categories:\n",
      "Proficiency in programming languages like SQL and Python - experience with dbt, spark, Airflow or Terraform is considered an asset\n",
      "Experience in the development code in a team using devops techniques and agile development methodologies\n",
      "Expertise in working with various Data Warehouse solutions and constructing data products using technologies such as Snowflake, Databricks, Azure Data Engineering Stack (like storage accounts, key vaults, Synapse, MSSQL, etc.)\n",
      "Understanding of data warehouse modelling methodologies (Kimball, data vault et al.) as well as concepts like data mesh or similar\n",
      " \n",
      "On a personal level, we anticipate that you:\n",
      "Possess a collaborative and open-minded nature, eager to contribute to a globally diverse cross-functional team within the organization\n",
      "Display curiosity and motivation for developing innovative data products that generate value exhibing positive communication skills, coupled with a positive, problem-solving approach to accomplishing tasks\n",
      "Thrive in diverse environments and exhibit flexibility in adapting to evolving conditions embracing a commitment to continuous learning and a desire to contribute to the collective growth of the team\n",
      " \n",
      "What we offer \n",
      "\n",
      "You will join a newly established, innovative, and committed team committed to support the business through the development of enterprise data products. You will also have the possibility to be part of forming how to best build data products. You will experience an environment that promotes continuous learning, enabling you to actualize your ambitions and get the chance to work in an agile office environment. While we hold our team members to high individual standards of collaboration, accountability, and meeting deadlines, we provide unwavering support to one another, collectively celebrating successes and addressing challenges.\n",
      "\n",
      "\n",
      "\n",
      "------ Retrieving cover letter template ------\n",
      "cover_letter_template [(Document(page_content=\"Data Scientist\\n\\nI reached out due to my interest in AI, Software Development/Engineering, and Knowledge management.\\n\\nMotivation I am driven to progress in the field of AI, particularly focusing on Large Language Models, knowledge extraction, and Natural Language Processing. My goal is to ensure that every AI implementation has a solid foundation of reliable data. I am dedicated to setting up thorough data agreements to back these efforts and am excited about the prospect of working alongside your team. My passion for AI is motivated by genuine curiosity and the satisfaction derived from tackling complex problems. Whether working independently or as part of a team, I am committed to addressing every necessary element to deliver a well-rounded AI solution, including aspects of security and compliance with GDPR and AI-ACT. I am enthusiastic about engaging in an environment that encourages detailed and strategic discussions on AI applications. It aligns perfectly with my career objectives. Contributing to projects that cover DevOps, DevSecOps, and MLOps, and incorporating the latest AI innovations into actionable solutions, is very interesting. The demands of this role, particularly the need for effective communication among various stakeholders combined with a keen interest in continuous learning, position me as a promising long-term candidate with fresh ideas. Addressing all facets essential to a robust AI solution, including security measures and adherence to GDPR & AI-ACT standards, is integral.\\n\\nI am keen to bring my personal interest in AI trends into practical scenarios, engaging with peers who share a similar enthusiasm. I see great potential in directly adding value by developing data pipelines, enhancing knowledge retention, fostering rapid innovation, and considering legal and ethical aspects throughout the AI solution lifecycle through active collaboration. My character thrives in dynamic and challenging settings, making me an ideal fit for the Full-stack Data Scientist role you offer.\\n\\nSkills My experience spans various settings, from everyday to luxury environments in the hospitality industry, where I developed strong communication skills. My prior experiences equipped me to translate business needs into technical requirements effectively. I am committed to sustainable solutions and consistently strive to align project objectives with broader business goals.\\n\\nEducation In the summer of 2023, I completed my Master's degree in Data Science ICT. My thesis utilized foundational transformer models to semi-automatically generate PEST analyses, which were enhanced with Named Entity Recognition and summarization techniques. This project involved analyzing publicly available data to provide macroeconomic insights, particularly concerning market expansion. The objective was to synthesize summaries from vectorized unstructured data, retrieving information based on semantic similarity and ranking through general-purpose language models.\\n\\nAdditionally, I hold a Professional Bachelor's Degree in Economics & IT. For my bachelor's thesis, I developed an enterprise architecture strategy for EnviroProcess Denmark and its parent company, EnviroProcess AB. This strategy was designed to align IT initiatives with the subsidiarys core competencies, specific service knowledge, unique industry insights, and overall project execution.\\n\\nContinued Learning I am committed to continuously enhancing my skills and am currently exploring areas such as knowledge engineering, decision intelligence, and multi-agent learning frameworks. Additionally, I open to learn what is needed and I try to stay current with the latest advancements in AI, particularly within the domains of NLP and generative AI.\\n\\nThank you for your time I look forward to the chance to discuss how my background, ambitions, and the alignment with the goals of [Company Name]. I am enthusiastic about potentially contributing to your projects and would appreciate the opportunity to discuss this further.\", metadata={'source': 'jobtemplates/ai_engineer_generative.txt', '_id': 'fe4b063b32c1452e8ea3037ec72ee3ba', '_collection_name': 'f0c0d505b7054a68ade00f02d86a90f4'}), 0.6413844082895206)]\n",
      "------ Analysing vacancy ------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Checkpoints are accessed by thread_id\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: thread_id,\n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, query_for_search], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}, config\u001b[38;5;241m=\u001b[39mconfig, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m     14\u001b[0m     _print_event(event, _printed)\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langgraph/pregel/__init__.py:876\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    869\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    870\u001b[0m     futures,\n\u001b[1;32m    871\u001b[0m     return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[1;32m    872\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m    873\u001b[0m )\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# combine pending writes from all tasks\u001b[39;00m\n\u001b[1;32m    879\u001b[0m pending_writes \u001b[38;5;241m=\u001b[39m deque[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]()\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1422\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1420\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langgraph/pregel/retry.py:66\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     64\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langchain_core/runnables/base.py:2399\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2399\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langgraph/utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, config)\n\u001b[1;32m     90\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config}\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[26], line 51\u001b[0m, in \u001b[0;36manalyse_vacancy\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     48\u001b[0m error \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     49\u001b[0m cover_letter_template \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcover_letter_template\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 51\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_letter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcover_letter_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------ CONDUCTING ANALYSIS ------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: iterations,\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: error,\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\n\u001b[1;32m     58\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langchain_core/runnables/base.py:2399\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2399\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:171\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    169\u001b[0m         ChatGeneration,\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m--> 171\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[1;32m    172\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    173\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    174\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    175\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    176\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    177\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    179\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/bumstuff/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:154\u001b[0m, in \u001b[0;36mBaseChatModel._convert_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mconvert_to_messages(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "events = graph.stream({'messages': ['user', query_for_search], 'iterations': 0}, config=config, stream_mode='values')\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    _print_event(event, _printed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events:\n",
    "    _print_event(event)\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of allowed words: 459\n",
      "Number of forbidden words used: 2\n",
      "Forbidden words used: ['seamlessly', 'enhancing']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def validate_words(do_not_use_words, *args):\n",
    "    false_count = 0\n",
    "    true_count = 0\n",
    "\n",
    "    forbidden_words_used = []\n",
    "\n",
    "    for arg in args:\n",
    "        words = arg.split()\n",
    "        for word in words:\n",
    "            if word in do_not_use_words:\n",
    "                false_count += 1\n",
    "                forbidden_words_used.append(word)\n",
    "            else:\n",
    "                true_count += 1\n",
    "    \n",
    "    # Return a tuple with the counts and the list of forbidden words used\n",
    "    return true_count, false_count, forbidden_words_used\n",
    "\n",
    "true_count, false_count, forbidden_words_used = validate_words(\n",
    "    do_not_use_words,\n",
    "    final_company_name, final_jobtitle, final_introduction, final_motivation, \n",
    "    final_skills, final_masters, final_bachelors,  final_continued_learning, \n",
    "    final_thank_you\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of allowed words: {true_count}\")\n",
    "print(f\"Number of forbidden words used: {false_count}\")\n",
    "print(f\"Forbidden words used: {forbidden_words_used}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of safe texts: 4\n",
      "Number of modified texts: 5\n"
     ]
    }
   ],
   "source": [
    "#some regex to remove characters that intervene with latex commands\n",
    "def check_latex_safety(*args):\n",
    "    # Dictionary to map LaTeX special characters to their safe equivalents\n",
    "    replacements = {\n",
    "        '\\\\': ' ',          # backslash to space\n",
    "        '{': ' ',           # curly brace to space\n",
    "        '}': ' ',           # curly brace to space\n",
    "        '#': ' ',           # hash to space\n",
    "        '%': ' ',           # percent to space\n",
    "        '&': 'and',         # ampersand to 'and'\n",
    "        '_': ' ',           # underscore to space\n",
    "        '^': ' ',           # caret to space\n",
    "        '~': ' ',           # tilde to space\n",
    "        '$': 'dollars',     # dollar to space\n",
    "        '/': ' ',           # slash to space\n",
    "        '*': ' ',           # asterisk to space\n",
    "        '-': ' '            # hyphen to space\n",
    "    }\n",
    "    \n",
    "    # Regex pattern to match any LaTeX special character\n",
    "    pattern = r'[\\\\{}#%&_^\\~$\\/\\*\\-]'\n",
    "    \n",
    "    true_count = 0\n",
    "    false_count = 0\n",
    "\n",
    "    # Function to replace matched characters\n",
    "    def replace_match(match):\n",
    "        return replacements[match.group(0)]\n",
    "    \n",
    "    # Process each input text\n",
    "    results = []\n",
    "    for text in args:\n",
    "        if re.search(pattern, text):\n",
    "            false_count += 1\n",
    "            safe_text = re.sub(pattern, replace_match, text)\n",
    "        else:\n",
    "            true_count += 1\n",
    "            safe_text = text\n",
    "        results.append(safe_text)\n",
    "\n",
    "    print(f\"Number of safe texts: {true_count}\")\n",
    "    print(f\"Number of modified texts: {false_count}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "(final_company_name, \n",
    " final_jobtitle, \n",
    " final_introduction, \n",
    " final_motivation, \n",
    " final_skills, \n",
    " final_masters, \n",
    " final_bachelors, \n",
    " final_continued_learning, \n",
    " final_thank_you) = check_latex_safety(\n",
    "                                        final_company_name, \n",
    "                                        final_jobtitle, \n",
    "                                        final_introduction, \n",
    "                                        final_motivation, \n",
    "                                        final_skills, \n",
    "                                        final_masters, \n",
    "                                        final_bachelors, \n",
    "                                        final_continued_learning, \n",
    "                                        final_thank_you)\n",
    "\n",
    "# Directory where the variables.tex file will be saved\n",
    "directory = 'companies_applied_for'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "company_directory = os.path.join(directory, final_company_name)\n",
    "if not os.path.exists(company_directory):\n",
    "    os.makedirs(company_directory)\n",
    "\n",
    "# Write these variables to a .tex file in the specified directory\n",
    "resume_file_path = os.path.join(company_directory, final_company_name + '.tex')\n",
    "with open(resume_file_path, 'w') as text_for_latex:\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalCompanyName}}{{{final_company_name}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalJobtitle}}{{{final_jobtitle}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalIntroduction}}{{{final_introduction}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalMotivation}}{{{final_motivation}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalSkills}}{{{final_skills}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalEducationMaster}}{{{final_masters}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalEducationBachelor}}{{{final_bachelors}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalContinuedLearning}}{{{final_continued_learning}}}\\n\")\n",
    "    text_for_latex.write(f\"\\\\newcommand{{\\\\finalThankYou}}{{{final_thank_you}}}\\n\")\n",
    "\n",
    "latex_filename = f'JMangabat_{final_company_name}_{final_jobtitle}_{current_date}.tex'\n",
    "\n",
    "latex_file_path = os.path.join(company_directory, latex_filename)\n",
    "\n",
    "# Check if the file already exists and create a unique file name if it does\n",
    "file_counter = 1\n",
    "while os.path.exists(latex_file_path):\n",
    "    new_file_name = f'JMangabat_{final_company_name}_{final_jobtitle}_{current_date}_{file_counter}.tex'\n",
    "    latex_file_path = os.path.join(company_directory, new_file_name)\n",
    "    file_counter += 1\n",
    "\n",
    "template_tex = \"main_setup.tex\"\n",
    "\n",
    "tex_content = tex_content = f\"\"\"\n",
    "%----------------------------------------------------------------------------------------\n",
    "% PACKAGES AND OTHER DOCUMENT CONFIGURATIONS\n",
    "%----------------------------------------------------------------------------------------\n",
    "\n",
    "\\\\documentclass{{article}}\n",
    "% \\\\usepackage{{charter}} % Use the Charter font\n",
    "\\\\usepackage{{graphicx}} % Required for including images\n",
    "\\\\usepackage{{fancyhdr}} % Required for customizing headers and footers\n",
    "\\\\usepackage{{setspace}} % Remove paragraph indentation\n",
    "\\\\usepackage{{titlesec}} % Used to customize the \\\\section command\n",
    "\\\\usepackage[\n",
    "    a4paper, % Paper size\n",
    "    top=15mm, % Top margin\n",
    "    bottom=15mm, % Bottom margin\n",
    "    left=15mm, % Left margin\n",
    "    right=15mm, % Right margin\n",
    "    % showframe % Uncomment to show frames around the margins for debugging purposes\n",
    "]{{geometry}}\n",
    "\n",
    "% \\\\setlength{{\\\\parindent}}{{0pt}} % Paragraph indentation\n",
    "\\\\setlength{{\\\\parskip}}{{-0.7em}} % Vertical space between paragraphs\n",
    "\n",
    "\\\\fancypagestyle{{firstpage}}{{%\n",
    "    \\\\fancyhf{{}} % Clear default headers/footers\n",
    "    \\\\renewcommand{{\\\\headrulewidth}}{{0pt}} % No header rule\n",
    "    \\\\renewcommand{{\\\\footrulewidth}}{{1pt}} % Footer rule thickness\n",
    "}}\n",
    "\n",
    "\\\\fancypagestyle{{subsequentpages}}{{%\n",
    "    \\\\fancyhf{{}} % Clear default headers/footers\n",
    "    \\\\renewcommand{{\\\\headrulewidth}}{{1pt}} % Header rule thickness\n",
    "    \\\\renewcommand{{\\\\footrulewidth}}{{1pt}} % Footer rule thickness\n",
    "}}\n",
    "\n",
    "\\\\input{{variables.tex}}\n",
    "\n",
    "\\\\AtBeginDocument{{\\\\thispagestyle{{firstpage}}}} % Use the first page headers/footers style on the first page\n",
    "\\\\pagestyle{{subsequentpages}} % Use the subsequent pages headers/footers style on subsequent pages\n",
    "%----------------------------------------------------------------------------------------\n",
    "%----------------------------------------------------------------------------------------\n",
    "\\\\begin{{document}}\n",
    "\\\\rule{{\\\\linewidth}}{{1pt}} % Horizontal rule\n",
    "\n",
    "% Use the commands in your document\n",
    "\\\\begin{{center}}\n",
    "    Jannik M. B. Srensen |\n",
    "    Email: Mangabat93@gmail.com | \n",
    "    Odder, Denmark | Date\n",
    "\\\\end{{center}}\n",
    "\n",
    "\\\\subsection*{{\\\\finalJobtitle, \\\\finalCompanyName}}\n",
    "    \\\\begin{{spacing}}{{1.2}}\n",
    "        {{\\\\finalIntroduction}}\n",
    "    \\\\end{{spacing}}\n",
    "    \\\\vspace*{{0mm}}\n",
    "\n",
    "\\\\subsection*{{Motivation}}\n",
    "    \\\\begin{{spacing}}{{1.2}}\n",
    "        {{\\\\finalMotivation}}\n",
    "    \\\\end{{spacing}}\n",
    "    \\\\vspace*{{0mm}}\n",
    "\n",
    "\\\\subsection*{{Skills}}\n",
    "    \\\\begin{{spacing}}{{1.2}}\n",
    "        {{\\\\finalSkills}}\n",
    "    \\\\end{{spacing}}\n",
    "    \\\\vspace*{{0mm}}\n",
    "\n",
    "\\\\subsection*{{Education}}\n",
    "% Masters degree\n",
    "    \\\\begin{{spacing}}{{1.2}}\n",
    "        {{\\\\finalEducationMaster}}\\\\\\\\\n",
    "        % Bachelors degree\n",
    "        {{\\\\finalEducationBachelor}}\n",
    "    \\\\end{{spacing}}\n",
    "    \\\\vspace*{{0mm}}\n",
    "\n",
    "\\\\subsection*{{Continued Learning}}\n",
    "    \\\\begin{{spacing}}{{1.2}}\n",
    "        {{\\\\finalContinuedLearning}}\n",
    "    \\\\end{{spacing}}\n",
    "    \\\\vspace*{{0mm}}\n",
    "\n",
    "\\\\subsection*{{Thanks for your time}}\n",
    "    \\\\begin{{spacing}}{{1.2}}\n",
    "        {{\\\\finalThankYou}}\\\\\\\\        \n",
    "    \\\\end{{spacing}}\n",
    "\n",
    "\\\\noindent Kind regards,\\\\\\\\\n",
    "    Jannik Mangabat\n",
    "%----------------------------------------------------------------------------------------\n",
    "% LETTER CONTENT\n",
    "%----------------------------------------------------------------------------------------\n",
    "\n",
    "\\\\end{{document}}\n",
    "\"\"\"\n",
    "\n",
    "with open(latex_file_path, 'w') as file:\n",
    "    file.write(tex_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bumstuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
